{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7864a5f1",
   "metadata": {},
   "source": [
    "## Resume Parser "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392ae44",
   "metadata": {},
   "source": [
    "### 1. Data Gathering and Processing\n",
    "\n",
    "To create a diverse and representative dataset for this project, I gathered a small set of **7 synthetic resumes** in both PDF and Word formats. This approach ensures the solution is not overfitted to any specific resume style and can handle variations in document structure. This small sample will also be used for evaluating the project's performance.\n",
    "\n",
    "The resume samples were sourced from the following platforms:\n",
    "\n",
    "* **Indeed Resume Builder** ([www.resume.com](https://www.resume.com)): I created and downloaded **3 resumes in PDF format** using this free tool. The profile information (names, emails, and skills) was generated using an AI tool (Gemini 2.5 Flash) to ensure the data was fictitious and unique to this project.\n",
    "* **Microsoft 365 Resume Templates** ([create.microsoft.com/en-us/templates/resumes](https://create.microsoft.com/en-us/templates/resumes)): To obtain samples in the **Word (.docx) format**, I utilized the free resume template bank provided by Microsoft. I created and downloaded **4 resumes in .docx format**. These templates cover a range of professional layouts and designs, which helps in testing the robustness of the parsing algorithm across different document structures.\n",
    "\n",
    "By using these methods, I was able to create a small but effective dataset to develop and evaluate the resume parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce99721",
   "metadata": {},
   "source": [
    "### 2. Proof of Concept (POC) and System Design\n",
    "\n",
    "The development of this resume parser will follow a **Test-Driven Development (TDD)** approach. This means we will start by writing tests that specify the expected behavior of our solution. These tests will serve as our development roadmap, ensuring that our code correctly handles the required inputs and produces the desired structured output.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2.1. Overall System Pipeline\n",
    "\n",
    "The core of this project is a robust pipeline designed to extract structured information from various resume file formats. The proposed system design is a multi-step process that leverages specialized libraries for document conversion and the power of a large language model (LLM) for intelligent information extraction.\n",
    "\n",
    "The high-level pipeline can be summarized as follows:\n",
    "\n",
    "1.  **TDD Driver**: The development begins with test cases written in `pytest`, which define the expected `name`, `email`, and `skills` for our sample resumes.\n",
    "2.  **Document Ingestion**: The system accepts resumes in either PDF or Word (.docx) format.\n",
    "3.  **Document-to-Markdown Conversion**: Both file types are converted into a standardized Markdown format. This is a critical step, as Markdown preserves key structural elements (like headings, lists, and bold text) while creating a clean, text-based representation. This format is also ideal for processing by LLMs, as they are often pre-trained on a vast corpus of Markdown text, leading to more predictable and accurate results.\n",
    "4.  **LLM-based Information Extraction**: The Markdown text of the resume is passed to a powerful LLM with a carefully crafted prompt. The prompt directs the LLM to identify and extract the candidate's name, email, and skills.\n",
    "5.  **Structured Output Generation**: The LLM is configured to return the extracted information in a structured JSON format, ensuring a clean and consistent output.\n",
    "6.  **Output Validation**: The final JSON object is validated against a defined schema, and the test cases verify that the output matches the ground truth.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2.2. Technical Stack and Tooling\n",
    "\n",
    "To implement this pipeline, I propose using a specific set of tools and packages for each step, balancing efficiency, cost, and maintainability.\n",
    "\n",
    "**Testing:**\n",
    "\n",
    "* The project will be **test-driven using `pytest`**. Tests will be written to fail initially, guiding the implementation of the parsing logic until they pass. This ensures all functionality is verified and provides a safety net for future refactoring.\n",
    "\n",
    "**Document Conversion:**\n",
    "\n",
    "* **Word (.docx) to Markdown**: The `markdown-it-doc` package is the primary choice for its reliability in converting Microsoft Word documents to Markdown. As a fallback, `pandoc` can be used, a versatile command-line tool known for its extensive support for various document conversions.\n",
    "* **PDF to Markdown**: For PDF parsing, `pymupdf4llm` will be leveraged. This library is specifically designed to handle the complexities of PDF layouts and produce LLM-friendly output. It provides a more robust solution compared to general-purpose PDF-to-text libraries. A simple fallback would be `PyMuPDF`, which offers basic text extraction capabilities.\n",
    "\n",
    "**LLM and Prompt Engineering:**\n",
    "\n",
    "* **LLM Service**: The API from [OpenRouter](https://openrouter.ai/) will be used to access various LLMs, prioritizing **`Gpt4-mini`** due to its low cost and strong performance. This choice balances accuracy with cost-effectiveness.\n",
    "* **Structured Output**: A key challenge with the OpenRouter API is the lack of explicit, well-documented support for structured output formats (like a JSON schema). To address this, a robust method will be implemented using a combination of a well-designed prompt and the Python `pydantic` library.\n",
    "    * **Prompting**: The LLM will be given clear instructions to return the output in a specific JSON format, explicitly listing the keys (`name`, `email`, `skills`) and their corresponding data types.\n",
    "    * **Pydantic**: The `pydantic` library will be used to define a data model that mirrors the required JSON schema. The LLM's output will be passed to this model, which will handle the parsing and validation. This approach ensures the final output is always in the correct format, handles potential parsing errors gracefully, and provides clear type-hinting for clean code.\n",
    "\n",
    "**Project Management and Development Practices:**\n",
    "\n",
    "* **Environment Management**: `uv` will be used for project and dependency management.\n",
    "* **Version Control**: Git will be used for source control, with the project hosted on a private GitHub repository for development, which will be made public upon completion to satisfy the project requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a8d81",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99133675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from markitdown import MarkItDown\n",
    "import dotenv\n",
    "import requests\n",
    "import json\n",
    "from typing import Type, List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f5c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load openrouter api key\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f499a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resume_parser():\n",
    "    \"\"\"Simple TDD test function with multiple test cases\"\"\"\n",
    "    parser = ResumeParser()\n",
    "    \n",
    "    # Test case 1: Classic management resume (DOCX)\n",
    "    print(\"Testing Classic management resume...\")\n",
    "    result1 = parser(\"./data/inputs/Classic management resume.docx\")\n",
    "    expected1 = {\n",
    "        \"name\": \"Carmelo Barese\",\n",
    "        \"email\": \"carmelo@example.com\",\n",
    "        \"skills\": [\"Marketing\", \"Communication\", \"Project management\", \"Problem-solving\", \"Budget planning\"]\n",
    "    }\n",
    "    \n",
    "    assert result1[\"name\"] == expected1[\"name\"], f\"Test 1 - Name: Expected {expected1['name']}, got {result1['name']}\"\n",
    "    assert result1[\"email\"] == expected1[\"email\"], f\"Test 1 - Email: Expected {expected1['email']}, got {result1['email']}\"\n",
    "    assert set(s.lower() for s in result1[\"skills\"]) == set(s.lower() for s in expected1[\"skills\"]), f\"Test 1 - Skills mismatch\"\n",
    "    print(\"✅ Test 1 passed!\")\n",
    "    print(\"Testing Sam Lee resume...\")\n",
    "    result2 = parser(\"data/inputs/cv_samantha_lee.docx\")\n",
    "    expected2 = {\n",
    "        \"name\": \"Samantha Lee\",\n",
    "        \"email\": \"sam.lee@college.harvard.edu\",\n",
    "        \"skills\": [\"Adobe Creative Suite\", \"Typography\", \"Web Design\", \"Illustration\"]\n",
    "    }\n",
    "    \n",
    "    assert result2[\"name\"] == expected2[\"name\"], f\"Test 2 - Name: Expected {expected2['name']}, got {result2['name']}\"\n",
    "    assert result2[\"email\"] == expected2[\"email\"], f\"Test 2 - Email: Expected {expected2['email']}, got {result2['email']}\"\n",
    "    assert set(s.lower() for s in result2[\"skills\"]) == set(s.lower() for s in expected2[\"skills\"]), f\"Test 2 - Skills mismatch, got {result2['skills']}\"\n",
    "    print(\"✅ Test 2 passed!\")\n",
    "\n",
    "    print(\"Testing Geometrix resume...\")\n",
    "    result3 = parser(\"data/inputs/Geometric resume.docx\")\n",
    "    expected3 = {\n",
    "        \"name\": \"Yuuri Tanaka\",\n",
    "        \"email\": \"yuuri@example.com\",\n",
    "        \"skills\": [\"Creativity\", \"Leadership\", \"Organization\", \"Problem solving\", \"Teamwork\"]\n",
    "    }\n",
    "    \n",
    "    assert result3[\"name\"] == expected3[\"name\"], f\"Test 3 - Name: Expected {expected3['name']}, got {result3['name']}\"\n",
    "    assert result3[\"email\"] == expected3[\"email\"], f\"Test 3 - Email: Expected {expected3['email']}, got {result3['email']}\"\n",
    "    assert set(s.lower() for s in result3[\"skills\"]) == set(s.lower() for s in expected3[\"skills\"]), f\"Test 3 - Skills mismatch got {result3['skills']}\"\n",
    "    print(\"✅ Test 3 passed!\")\n",
    "\n",
    "    print(\"Testing Swiss Design resume...\")\n",
    "    result4 = parser(\"data/inputs/Swiss design resume.docx\")\n",
    "    expected4 = {\n",
    "        \"name\": \"Chanchal Sharma\",\n",
    "        \"email\": \"chanchals@example.com\",\n",
    "        \"skills\": [\"Data analysis\", \"Project management\", \"Communication\", \"Organization\", \"Problem solving\"]\n",
    "    }\n",
    "    \n",
    "    assert result4[\"name\"] == expected4[\"name\"], f\"Test 4 - Name: Expected {expected4['name']}, got {result4['name']}\"\n",
    "    assert result4[\"email\"] == expected4[\"email\"], f\"Test 4 - Email: Expected {expected4['email']}, got {result4['email']}\"\n",
    "    assert set(s.lower() for s in result4[\"skills\"]) == set(s.lower() for s in expected4[\"skills\"]), f\"Test 4 - Skills mismatch got {result4['skills']}\"\n",
    "    print(\"✅ Test 4 passed!\")\n",
    "    \n",
    "    # Test case 5: Customer Production Assistant resume (PDF)\n",
    "    print(\"Testing Customer Production Assistant resume...\")\n",
    "    result5 = parser(\"data/inputs/Customer Production Assistant Resume.pdf\")\n",
    "    expected5 = {\n",
    "        \"name\": \"Jessica Garcia\",\n",
    "        \"email\": \"jessgarcia@gmail.com\",\n",
    "        \"skills\": [\"Microsoft Office\", \"Basic Math\", \"Communication Skills\", \"Manufacturing\", \"Computer Skills\"]\n",
    "    }\n",
    "    assert result5[\"name\"] == expected5[\"name\"], f\"Test 5 - Name: Expected {expected5['name']}, got {result5['name']}\"\n",
    "    assert result5[\"email\"] == expected5[\"email\"], f\"Test 5 - Email: Expected {expected5['email']}, got {result5['email']}\"\n",
    "    assert set(s.lower() for s in result5[\"skills\"]) == set(s.lower() for s in expected5[\"skills\"]), f\"Test 5 - Skills mismatch got {result5['skills']}\"\n",
    "    print(\"✅ Test 5 passed!\")\n",
    "\n",
    "    print(\"Testing Dave Brown resume...\")\n",
    "    result6 = parser(\"data/inputs/Dave_Brown (1).pdf\")\n",
    "    expected6 = {\n",
    "        \"name\": \"David Brown\",\n",
    "        \"email\": \"dave.brown@yahoo.com\",\n",
    "        \"skills\": [\"Project Planning\", \"Budgeting\", \"Risk Management\", \"Gantt Charts\"]\n",
    "    }\n",
    "    assert result6[\"name\"] == expected6[\"name\"], f\"Test 6 - Name: Expected {expected6['name']}, got {result6['name']}\"\n",
    "    assert result6[\"email\"] == expected6[\"email\"], f\"Test 6 - Email: Expected {expected6['email']}, got {result6['email']}\"\n",
    "    assert set(s.lower() for s in result6[\"skills\"]) == set(s.lower() for s in expected6[\"skills\"]), f\"Test 6 - Skills mismatch got {result6['skills']}\"\n",
    "    print(\"✅ Test 6 passed!\")\n",
    "\n",
    "    print(\"Testing Ryan Wilson resume...\")\n",
    "    result7 = parser(\"data/inputs/Ryan_Wilson_cv.pdf\")\n",
    "    expected7 = {\n",
    "        \"name\": \"Ryan Wilson\",\n",
    "        \"email\": \"ryan.wilson@example.com\",\n",
    "        \"skills\": [\"Prototyping\", \"Robotics\", \"Project Management\", \"Technical Reporting\"]\n",
    "    }\n",
    "    assert result7[\"name\"] == expected7[\"name\"], f\"Test 7 - Name: Expected {expected7['name']}, got {result7['name']}\"\n",
    "    assert result7[\"email\"] == expected7[\"email\"], f\"Test 7 - Email: Expected {expected7['email']}, got {result7['email']}\"\n",
    "    assert set(s.lower() for s in result7[\"skills\"]) == set(s.lower() for s in expected7[\"skills\"]), f\"Test 7 - Skills mismatch got {result7['skills']}\"\n",
    "    print(\"✅ Test 7 passed!\")\n",
    "    \n",
    "    print(\"🎉 All tests passed! Both DOCX and PDF parsing work correctly.\")\n",
    "\n",
    "class ResumeProfile(BaseModel):\n",
    "    \"\"\"Structured Resume Profile informations.\"\"\"\n",
    "    name: str = Field(..., description=\"Full name of the candidate\")\n",
    "    email: str = Field(..., description=\"email address\")\n",
    "    skills: List[str] = Field(..., description=\"List of skills\")\n",
    "\n",
    "class ResumeParser:\n",
    "    DEFAULT_TASK_PROMPT = \"\"\"\n",
    "        You are an expert at extracting structured data from resumes.\n",
    "        Extract the full name, email and a list of skills from the provided resume content and return the data as a JSON object that matches specified schema.\n",
    "        In case a suite and the specific suite products are mentioned, only extract the suite (typically for Microsoft Office). Languages are no considered as skills.\n",
    "        If skill is generic, extract it.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, task_prompt: str = DEFAULT_TASK_PROMPT):\n",
    "        self.task_prompt = task_prompt\n",
    "        self.md_converter = MarkItDown(enable_plugins=False)\n",
    "        \n",
    "    def convert_to_md(self, filepath:str) -> str:\n",
    "        if filepath.endswith(\".pdf\"):\n",
    "            result =  self.md_converter.convert(filepath)\n",
    "            return result.text_content\n",
    "        elif filepath.endswith(\".docx\"):\n",
    "            result =  self.md_converter.convert(filepath)\n",
    "            return result.text_content\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only .docx is supported.\")\n",
    "  \n",
    "    def extract_resume_data_llm(\n",
    "        self,\n",
    "        resume_content: str,\n",
    "        output_model: Type[BaseModel] = ResumeProfile,\n",
    "        model: str = \"openai/gpt-4.1-mini\"\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Call LLM API to extract structured information from resume content.\n",
    "        \n",
    "        Args:\n",
    "            resume_content: Raw text content (markdown) of the resume to analyze\n",
    "            task_prompt: Custom system prompt for the LLM\n",
    "            output_model: Pydantic model class for response validation\n",
    "            model: LLM model identifier to use\n",
    "        \n",
    "        Returns:\n",
    "            Optional[Dict[str, Any]]: Structured resume data if successful, None on failure\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If API response is invalid\n",
    "            requests.RequestException: For API communication errors\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create model instance for schema validation\n",
    "            generated_schema = output_model.model_json_schema()\n",
    "            api_schema_payload = {\n",
    "                \"name\": \"ResumeProfile\",\n",
    "                \"strict\": True,\n",
    "                \"schema\": {\n",
    "                    **generated_schema,\n",
    "                    \"additionalProperties\": False \n",
    "                }\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                headers={\n",
    "                    \"Authorization\": f\"Bearer {os.getenv('API_KEY')}\",\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                },\n",
    "                json={\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": self.task_prompt},\n",
    "                        {\"role\": \"user\", \"content\": resume_content},\n",
    "                    ],\n",
    "                    \"response_format\": {\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"json_schema\": api_schema_payload\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "\n",
    "            data = response.json()\n",
    "            if \"choices\" not in data or not data[\"choices\"]:\n",
    "                raise ValueError(\"Invalid API response format\")\n",
    "                \n",
    "            content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "            # Validate and convert to dict\n",
    "            parsed_data = output_model.model_validate_json(content)\n",
    "            return parsed_data.model_dump()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"API request failed: {str(e)}\")\n",
    "            return None\n",
    "        except ValueError as e:\n",
    "            print(f\"Data validation failed: {str(e)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, filepath):\n",
    "        # Implementation will go here - starts with failing test\n",
    "        md_content = self.convert_to_md(filepath)\n",
    "        res = self.extract_resume_data_llm(resume_content=md_content)\n",
    "        return res\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187a732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classic management resume...\n",
      "✅ Test 1 passed!\n",
      "Testing Sam Lee resume...\n",
      "✅ Test 2 passed!\n",
      "Testing Geometrix resume...\n",
      "✅ Test 3 passed!\n",
      "Testing Swiss Design resume...\n",
      "✅ Test 4 passed!\n",
      "Testing Customer Production Assistant resume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test 5 passed!\n",
      "Testing Dave Brown resume...\n",
      "✅ Test 6 passed!\n",
      "Testing Ryan Wilson resume...\n",
      "✅ Test 7 passed!\n",
      "🎉 All tests passed! Both DOCX and PDF parsing work correctly.\n"
     ]
    }
   ],
   "source": [
    "test_resume_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e83de9",
   "metadata": {},
   "source": [
    "### Technical Choices and Discussion\n",
    "\n",
    "#### Pragmatic Testing Strategy\n",
    "\n",
    "Given the time constraints of this technical assignment, a pragmatic approach was taken for evaluation and testing. Instead of setting up a formal testing framework like `pytest` and a dedicated test suite, the project's logic was validated using **simple `assert`-based tests**. This method allowed for quick verification of the core functionality directly within the Jupyter Notebook. The solution was tested against a small but diverse sample of **7 resumes**, ensuring the parser's ability to handle both DOCX and PDF formats. While this approach served the purpose of a Proof of Concept (POC), a production-grade solution would require a more comprehensive, framework-driven test suite to ensure robustness and full regression coverage.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iterative Prompt Engineering\n",
    "\n",
    "A key part of developing a reliable LLM-powered solution is the iterative refinement of the prompt. Initial testing revealed inconsistencies in the extracted skills. To address these, the prompt was fine-tuned with the following specific instructions:\n",
    "\n",
    "* **Suite vs. Product**: The prompt was refined to handle instances where a skill suite (e.g., \"Microsoft Office Suite\") and its specific products (e.g., \"Word,\" \"Excel\") were both mentioned. The final prompt's rule is to **only extract the suite** in such cases, ensuring a cleaner and more high-level skills list.\n",
    "* **Inclusion of Generic Skills**: Initial prompt versions tended to miss fundamental, generic skills that were not associated with a specific technology, such as \"Communication\" or \"Basic Math.\" The prompt was updated with an explicit instruction to extract these generic skills, improving the comprehensiveness of the output.\n",
    "* **Exclusion of Languages**: Based on the project's definition of \"skills,\" the prompt was explicitly instructed to **not consider languages** as skills, preventing the extraction of items like \"English\" or \"French\" and maintaining the focus on professional, technical proficiencies.\n",
    "\n",
    "---\n",
    "\n",
    "#### Defining \"What is a Skill?\"\n",
    "\n",
    "A significant challenge in building a generic resume parser is the ambiguity surrounding the term \"skill.\" While this assignment used a heuristic approach, a robust, production-level system would require a more structured solution. This can be viewed as a **knowledge management** or **ontology** problem.\n",
    "\n",
    "* **Need for a Standard**: To ensure consistent and high-quality extractions, a formal definition of a \"skill\" is required. This would involve a standardized list or a taxonomy to prevent ambiguity and ensure that a skill is recognized uniformly across all resumes.\n",
    "* **Collaboration with Stakeholders**: Defining this standard would necessitate collaboration with Subject Matter Experts (SMEs) and other stakeholders. This would be a crucial next step to transition the POC into a deployable solution, ensuring the extracted skills are relevant and meaningful to the business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f6e88",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "\n",
    " We will conduct an assessment across two key dimensions: effectiveness (accuracy) and efficiency (performance). For effectiveness, we will employ a retrieval-based methodology where the parser's output for each resume is compared against the manually verified ground truth. This will yield quantitative metrics including Precision, Recall, and F1-score for the skills list—which accommodates partial matches—and exact-match accuracy for the name and email fields.\n",
    "\n",
    " Regarding the efficiency metrics, we will compute processing time  related metrics based on the distribution of processing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d5107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "F1-Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "def calculate_skill_metrics(parsed_skills, gold_skills):\n",
    "    \"\"\"\n",
    "    Calculate Precision, Recall, and F1-Score for skills lists.\n",
    "    Converts lists to sets for comparison.\n",
    "    \n",
    "    Args:\n",
    "        parsed_skills (list): List of skills extracted by the parser.\n",
    "        gold_skills (list): List of skills from the gold standard.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing precision, recall, and f1 score.\n",
    "    \"\"\"\n",
    "    # Convert to sets for set operations\n",
    "    parsed_set = set(skill.strip().lower() for skill in parsed_skills)\n",
    "    gold_set = set(skill.strip().lower() for skill in gold_skills)\n",
    "\n",
    "    # Calculate True Positives (correctly extracted), etc.\n",
    "    true_positives = len(parsed_set & gold_set) # Intersection\n",
    "    false_positives = len(parsed_set - gold_set) # Skills in parsed but not in gold\n",
    "    false_negatives = len(gold_set - parsed_set) # Skills in gold but not in parsed\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives\n",
    "    }\n",
    "\n",
    "# Example usage in your notebook\n",
    "gold_skills = [\"Python\", \"Machine Learning\", \"SQL\", \"AWS\"]\n",
    "parsed_skills = [\"Python\", \"Java\", \"AWS\", \"Data Analysis\"]\n",
    "\n",
    "metrics = calculate_skill_metrics(parsed_skills, gold_skills)\n",
    "print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "print(f\"F1-Score: {metrics['f1_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf6b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Golden benchmark for resume parser tests.\n",
    "This file contains the expected output for each resume file.\n",
    "\"\"\"\n",
    "\n",
    "GOLDEN_BENCHMARK = {\n",
    "    \"data/inputs/Classic management resume.docx\": {\n",
    "        \"name\": \"Carmelo Barese\",\n",
    "        \"email\": \"carmelo@example.com\",\n",
    "        \"skills\": [\"Marketing\", \"Communication\", \"Project management\", \"Problem-solving\", \"Budget planning\"]\n",
    "    },\n",
    "    \"data/inputs/cv_samantha_lee.docx\": {\n",
    "        \"name\": \"Samantha Lee\",\n",
    "        \"email\": \"sam.lee@college.harvard.edu\",\n",
    "        \"skills\": [\"Adobe Creative Suite\", \"Typography\", \"Web Design\", \"Illustration\"]\n",
    "    },\n",
    "    \"data/inputs/Geometric resume.docx\": {\n",
    "        \"name\": \"Yuuri Tanaka\",\n",
    "        \"email\": \"yuuri@example.com\",\n",
    "        \"skills\": [\"Creativity\", \"Leadership\", \"Organization\", \"Problem solving\", \"Teamwork\"]\n",
    "    },\n",
    "    \"data/inputs/Swiss design resume.docx\": {\n",
    "        \"name\": \"Chanchal Sharma\",\n",
    "        \"email\": \"chanchals@example.com\",\n",
    "        \"skills\": [\"Data analysis\", \"Project management\", \"Communication\", \"Organization\", \"Problem solving\"]\n",
    "    },\n",
    "    \"data/inputs/Customer Production Assistant Resume.pdf\": {\n",
    "        \"name\": \"Jessica Garcia\",\n",
    "        \"email\": \"jessgarcia@gmail.com\",\n",
    "        \"skills\": [\"Microsoft Office\", \"Basic Math\", \"Communication Skills\", \"Manufacturing\", \"Computer Skills\"]\n",
    "    },\n",
    "    \"data/inputs/Dave_Brown (1).pdf\": {\n",
    "        \"name\": \"David Brown\",\n",
    "        \"email\": \"dave.brown@yahoo.com\",\n",
    "        \"skills\": [\"Project Planning\", \"Budgeting\", \"Risk Management\", \"Gantt Charts\"]\n",
    "    },\n",
    "    \"data/inputs/Ryan_Wilson_cv.pdf\": {\n",
    "        \"name\": \"Ryan Wilson\",\n",
    "        \"email\": \"ryan.wilson@example.com\",\n",
    "        \"skills\": [\"Prototyping\", \"Robotics\", \"Project Management\", \"Technical Reporting\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb471381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/inputs/Geometric resume.docx\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'true_positives': 5, 'false_positives': 0, 'false_negatives': 0}\n",
      "data/inputs/Swiss design resume.docx\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'true_positives': 5, 'false_positives': 0, 'false_negatives': 0}\n",
      "data/inputs/Ryan_Wilson_cv.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.3076923076923077, 'recall': 1.0, 'f1_score': 0.47058823529411764, 'true_positives': 4, 'false_positives': 9, 'false_negatives': 0}\n",
      "data/inputs/Dave_Brown (1).pdf\n",
      "{'precision': 0.8, 'recall': 1.0, 'f1_score': 0.888888888888889, 'true_positives': 4, 'false_positives': 1, 'false_negatives': 0}\n",
      "data/inputs/Customer Production Assistant Resume.pdf\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'true_positives': 5, 'false_positives': 0, 'false_negatives': 0}\n",
      "data/inputs/Classic management resume.docx\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'true_positives': 5, 'false_positives': 0, 'false_negatives': 0}\n",
      "data/inputs/cv_samantha_lee.docx\n",
      "{'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'true_positives': 4, 'false_positives': 0, 'false_negatives': 0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>document</th><th>precision</th><th>recall</th><th>f1_score</th><th>true_positives</th><th>false_positives</th><th>false_negatives</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;data/inputs/Geometric resume.d…</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5</td><td>0</td><td>0</td></tr><tr><td>&quot;data/inputs/Swiss design resum…</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5</td><td>0</td><td>0</td></tr><tr><td>&quot;data/inputs/Ryan_Wilson_cv.pdf&quot;</td><td>0.307692</td><td>1.0</td><td>0.470588</td><td>4</td><td>9</td><td>0</td></tr><tr><td>&quot;data/inputs/Dave_Brown (1).pdf&quot;</td><td>0.8</td><td>1.0</td><td>0.888889</td><td>4</td><td>1</td><td>0</td></tr><tr><td>&quot;data/inputs/Customer Productio…</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5</td><td>0</td><td>0</td></tr><tr><td>&quot;data/inputs/Classic management…</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5</td><td>0</td><td>0</td></tr><tr><td>&quot;data/inputs/cv_samantha_lee.do…</td><td>1.0</td><td>1.0</td><td>1.0</td><td>4</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 7)\n",
       "┌────────────────┬───────────┬────────┬──────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ document       ┆ precision ┆ recall ┆ f1_score ┆ true_positives ┆ false_positive ┆ false_negativ │\n",
       "│ ---            ┆ ---       ┆ ---    ┆ ---      ┆ ---            ┆ s              ┆ es            │\n",
       "│ str            ┆ f64       ┆ f64    ┆ f64      ┆ i64            ┆ ---            ┆ ---           │\n",
       "│                ┆           ┆        ┆          ┆                ┆ i64            ┆ i64           │\n",
       "╞════════════════╪═══════════╪════════╪══════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ data/inputs/Ge ┆ 1.0       ┆ 1.0    ┆ 1.0      ┆ 5              ┆ 0              ┆ 0             │\n",
       "│ ometric        ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ resume.d…      ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/Sw ┆ 1.0       ┆ 1.0    ┆ 1.0      ┆ 5              ┆ 0              ┆ 0             │\n",
       "│ iss design     ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ resum…         ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/Ry ┆ 0.307692  ┆ 1.0    ┆ 0.470588 ┆ 4              ┆ 9              ┆ 0             │\n",
       "│ an_Wilson_cv.p ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ df             ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/Da ┆ 0.8       ┆ 1.0    ┆ 0.888889 ┆ 4              ┆ 1              ┆ 0             │\n",
       "│ ve_Brown       ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ (1).pdf        ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/Cu ┆ 1.0       ┆ 1.0    ┆ 1.0      ┆ 5              ┆ 0              ┆ 0             │\n",
       "│ stomer         ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ Productio…     ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/Cl ┆ 1.0       ┆ 1.0    ┆ 1.0      ┆ 5              ┆ 0              ┆ 0             │\n",
       "│ assic          ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ management…    ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ data/inputs/cv ┆ 1.0       ┆ 1.0    ┆ 1.0      ┆ 4              ┆ 0              ┆ 0             │\n",
       "│ _samantha_lee. ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "│ do…            ┆           ┆        ┆          ┆                ┆                ┆               │\n",
       "└────────────────┴───────────┴────────┴──────────┴────────────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run skills evaluation for each resume in the dataset\n",
    "parser = ResumeParser()\n",
    "skills_metrics_acc = []\n",
    "input_folder = \"data/inputs\"\n",
    "for resume_filepath in os.listdir(input_folder):\n",
    "    resume_filepath = os.path.join(input_folder, resume_filepath)\n",
    "    print(resume_filepath)\n",
    "    result = parser(resume_filepath)\n",
    "    result_skills= result[\"skills\"]\n",
    "    # retrieve golden labels from benchmark\n",
    "    ref = GOLDEN_BENCHMARK[resume_filepath]\n",
    "    ref_skills = ref[\"skills\"]\n",
    "    skills_metrics  = calculate_skill_metrics(parsed_skills=result_skills, gold_skills=ref_skills )\n",
    "    print(skills_metrics)\n",
    "    skills_metrics_acc.append({\"document\": resume_filepath, **skills_metrics, \"parsed\": result_skills})\n",
    "\n",
    "skills_metrics_df = pl.from_dicts(skills_metrics_acc)\n",
    "skills_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a84457",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
